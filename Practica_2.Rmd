---
title: "Practica 2"
author: "Daniel Rodriguez Fustes"
date: "29/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
print_kable = function(x) {
  print(kable_print_output <<- x)
  cat('\n')
}
```

## Ejercicio 1
### Elabore una funci√≥n que permita obtener una valoraci√≥n completa y personalizada de un modelo GLM. La funci√≥n, por tanto, deber√° obtener:
### - An√°lisis exploratorio, mediante tablas y gr√°ficos, de la relaci√≥n entre las variables independientes y la dependiente. Utilice para ello plot y gr√°ficos de correlaci√≥n, diagramas de caja, de densidad,‚Ä¶ Nota: distinguir, en funci√≥n del tipo de la variable dependiente, el tipo de modelo, regresi√≥n o clasificaci√≥n (funciones is.factor o is.numeric).
### - Una salida convenientemente formateada de los coeficientes estimados por el modelo, desviaciones est√°ndar, estad√≠stico t y sus p-valores, tanto en su versi√≥n cl√°sica (bajo los supuestos del modelo) como Bootstrap.
### - √çdem para las medidas de bondad del ajuste. Considere el R2, el R2 ajustado y el ECM para la regresi√≥n y el error de clasificaci√≥n y los pseudo R2 para clasificaci√≥n.
### - Resultados de los tests diagn√≥sticos del modelo: Shapiro-Wilk, Lilliefors, Levene/Brown-Forsythe, White, Breush-Godfrey, Durbin-Watson‚Ä¶ determinando si los residuos son normales, homoced√°sticos y aleatorios. Nota: mediante plot(modelo) ya se obtienen los tests gr√°ficos, pero puede personalizar la presentaci√≥n usando ggplot2 o cualquiera otra librer√≠a gr√°fica (lattice, plotrix, plotly,...). Dados los resultados obtenidos, la funci√≥n devolver√° un mensaje aconsejando utilizar o no el uso de los estimadores cl√°sicos o los de Bootstrap.
### - Incluya un par√°metro adicional, indicando si se desea realizar o no una selecci√≥n de variables y, de realizarse, de qu√© tipo: forward, backward, stepwise. Utilice como criterio el estad√≠stico BIC.
### Nota: para la obtenci√≥n de los estad√≠sticos Bootstrap puede basarse en los tres paquetes implementados en R: rsample, bootstrap o boot, o realizar una funci√≥n propia al efecto. Para problemas de clasificaci√≥n, realice el Bootstrap para cada clase por separado. Puede aprovechar las funciones de estad√≠stica descriptiva hechas para el preprocesado en el ejercicio anterior.
### Utilice el data frame BostonHousing del paquete mlbench para probar la funci√≥n en el caso de regresi√≥n, y para clasificaci√≥n (variable dependiente cualitativa) la ya preprocesada del ejercicio anterior.

```{r results='asis',echo=FALSE}
#Se cargan las librer√≠as necesarias.
suppressWarnings(suppressPackageStartupMessages(library(fitdistrplus)))
suppressWarnings(suppressPackageStartupMessages(library(rcompanion)))
suppressWarnings(suppressPackageStartupMessages(library(mlbench)))
suppressWarnings(suppressPackageStartupMessages(library(funModeling)))
suppressWarnings(suppressPackageStartupMessages(library(PerformanceAnalytics)))
suppressWarnings(suppressPackageStartupMessages(library(boot)))
suppressWarnings(suppressPackageStartupMessages(library(nortest)))
suppressWarnings(suppressPackageStartupMessages(library(lmtest)))
suppressWarnings(suppressPackageStartupMessages(library(kableExtra)))
suppressWarnings(suppressPackageStartupMessages(library(broom)))

#Se cargan los dataframes que se emplean en el ejercicio
data("BostonHousing")
BostonHousing<-as.data.frame(BostonHousing,stringsAsFactors = FALSE)
german.bal<-readRDS("30184602-german.balanceado.RDS.bin")
german.bal<-as.data.frame(german.bal,stringsAsFactors = FALSE)

#Se define la funci√≥n MLG que tiene tres argumentos: el primero es la variable dependiente, el segundo el dataframe que se va a analizar y el tercer argumento se refiere a si se desea que se realice un filtrado de variables de tipo stepwise,forward o backward.

#La funci√≥n ejecutar√° el modelo adecuado al tipo de dato que contenga la variable dependiente: num√©rico o factor. El modelo se desarollara sobre el dataframe que se indique. 

#NOTA SOBRE LOS ARGUMENTOS DE LA FUNCION MLG: Introducir el nombre de la variable dependiente entre comillas, por ejemplo, "crim". El nombre del dataframe empleado no debe ir entrecomillado, por ejemplo, BostonHousing. El tercer argumento debe ser completado con: "No","stepwise","forward" o "backward". Siendo el criterio del filtro el estad√≠stico BIC, calculado usando AIC con k=log(n).


MLG<-function(var_dep,dataframe,filtrado){
  
  #Filtra dejando los datos num√©ricos del dataframe
  dataframe_num<-Filter(is.numeric,dataframe)
  
  #Posici√≥n num√©rica de la variable elegida como dependiente
  posicion_var_dep<-which(colnames(dataframe)==var_dep)
  
  #Nombre de las variables del dataframe
  variables<-names(dataframe)
  
  #Nombre de la variable dependiente en funci√≥n de su posici√≥n en el dataframe
  depVar<-variables[posicion_var_dep]
  
  #Nombre de las variables independientes
  indepVars<-variables[-posicion_var_dep]
  
  #N√∫mero de columnas del dataframe
  numercol<-ncol(dataframe)
  
  #N√∫mero de columnas del dataframe numerico
  numercol.num<-ncol(dataframe_num)
  
  
  
  # Gr√°fico de densidad de las variables de tipo num√©rico
  cat('> **Gr√°ficos de densidad de las variables y sus distribuciones**','\n\n')
  for(columna in 1:numercol.num){
    plot.new()
    rect(par("usr")[1], par("usr")[3],par("usr")[2], par("usr")[4],col = "#f7f7f7")
    par(new = TRUE)
    plot(density(x=dataframe_num[,columna]),main=paste("Densidad",variables[columna]))
    fit_normal<-fitdist(dataframe_num[,columna],"norm")
    plot(fit_normal)
  }
  
  cat('','\n\n')
  
  # Gr√°fico de dispersi√≥n entre la variable dependiente y las independientes
  cat('> **Gr√°ficos de dispersi√≥n entre las variables dependiente e independientes**','\n\n')
  for(columna in 1:numercol){
    if(is.numeric(dataframe[,var_dep])){
    plot.new()
    rect(par("usr")[1], par("usr")[3],par("usr")[2], par("usr")[4],col = "#f7f7f7")
    par(new = TRUE)
    plot(x=dataframe[,var_dep],y=dataframe[,columna],
         main=paste("Correlaci√≥n entre variables:",var_dep," y ",variables[columna]),
         xlab=var_dep,ylab=variables[columna],las=1,cex.main=1,col="red")
    } else {
    plot.new()
    rect(par("usr")[1], par("usr")[3],par("usr")[2], par("usr")[4],col = "#f7f7f7")
    par(new = TRUE)
    plot(x=dataframe[,var_dep],y=dataframe[,columna],
         main=paste("Correlaci√≥n entre variables:",var_dep," y ",variables[columna]),
         xlab=var_dep,ylab=variables[columna],las=1,cex.main=1,col=rainbow(40))}
  }
  
  cat('','\n\n')
  
  # Correlaci√≥n entre la variable dependiente y cada una de las variables independientes
   cat('> **Tabla de correlaci√≥n entre las variables dependiente e independientes**','\n\n')
    if(is.numeric(dataframe[,var_dep])){
    correlacion<-correlation_table(dataframe_num,var_dep)
    print_kable(knitr::kable(correlacion)%>%kable_styling(bootstrap_options = "striped", full_width = F, position = "left"))          
                  
  } else{
    cat('No aplica puesto que la variable dependiente es de tipo factor','.\n\n')
  }
  
  #Correlaci√≥n entre las variables num√©ricas
   cat('> **Correlaci√≥n entre las variables num√©ricas**','\n\n')
   chart.Correlation(dataframe_num, histogram = F, pch = 10,floating= FALSE)
  
  cat('','\n\n')
  #ESTIMACI√ìN
  
  #Formula de regresi√≥n/clasificaci√≥n
  mi_formula <- as.formula(paste(depVar,sep = ' ~ ',paste(indepVars,collapse=' + ')))
  mi_formula.null <- as.formula(paste(depVar,sep = ' ~ ',paste(1)))
  
  #Se comprueba el tipo de dato de la variable dependiente y se carga el modelo adecuado
    if(is.numeric(dataframe[,var_dep])){
        full <- glm(mi_formula,data=dataframe,family = "gaussian")
        null <- glm(mi_formula.null,data=dataframe,family = "gaussian")
        #Regresi√≥n clasica
        #Chequeo de filtrado de variables
          if(filtrado=="backward"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC backward**','\n\n')
          regresion<-step(full, data=dataframe, scope=list(upper = full, lower = null), direction="backward",k=log(nrow(dataframe)))
          } else if (filtrado=="forward"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC forward**','\n\n')
          regresion<-step(null, data=dataframe, scope=list(upper = full, lower = null), direction="forward",k=log(nrow(dataframe)))
          } else if (filtrado=="stepwise"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC stepwise**','\n\n')
          regresion<-step(null, data=dataframe, scope=list(upper = full, lower = null), direction="both",k=log(nrow(dataframe)))
          } else if (filtrado=="No"){
          regresion<-glm(mi_formula,data=dataframe,family = "gaussian")
          }
        
          cat('','\n\n')
          
          cat('> **Modelo de regresi√≥n cl√°sico**','\n\n')
          print_kable(knitr::kable(tidy(regresion))%>%kable_styling(bootstrap_options = "striped"))
          
          #Error cuadr√°tico medio
          ECM<-sum(regresion$residuals^2)/regresion$df.residual
          cat('> **Error cuadr√°tico medio**','\n\n')
          cat(ECM)
          cat('','\n\n')
          
          #Medidas R2
          R2<-nagelkerke(regresion,restrictNobs = T)
          cat('> **Medidas de R^2^**','\n\n')
          print_kable(knitr::kable(R2$Pseudo.R.squared.for.model.vs.null)%>%kable_styling(bootstrap_options = "striped", full_width = F, position = "left"))
          
          
          #Gr√°fico de la regresi√≥n
          cat('> **Gr√°ficos de la regresi√≥n**','\n\n')
          plot(regresion)
          cat('','\n\n')
        
          #Verificaci√≥n de las hip√≥tesis del Modelo Lineal al 95% de confianza
          cat('> **Verificaci√≥n de las hip√≥tesis del modelo lineal**','\n\n')
            #Test de distribuci√≥n normal Saphiro-Wilk (para muestras peque√±as)
            cat('**Test de distribuci√≥n normal Saphiro-Wilk**','\n\n')
            saph<-shapiro.test(dataframe[,var_dep])
            print_kable(knitr::kable(tidy(saph))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(saph$p.value<0.05){cat("Distribuci√≥n de residuos no-normal")
            }else{cat("Distribuci√≥n normal")}
            cat('','\n\n')
            
            #Test de distribuci√≥n normal Lilliefors
            cat('**Test de distribuci√≥n normal Lilliefors**','\n\n')
            lillie<-lillie.test(dataframe[,var_dep])
            print_kable(knitr::kable(tidy(lillie))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(lillie$p.value<0.05){cat("Distribuci√≥n de residuos no-normal")
            }else{cat("Distribuci√≥n normal")}
            cat('','\n\n')
            
            #Test de heterocedasticidad de Breusch Pagan
            cat('**Test de heterocedasticidad de Breusch Pagan**','\n\n')
            bp<-bptest(regresion)
            print_kable(knitr::kable(tidy(bp))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(bp$p.value<0.05){cat("Residuos heteroced√°sticos")
            }else{cat("Residuos homoced√°sticos")}
            cat('','\n\n')
            
            #Test de autocorrelaci√≥n de Breush-Godfrey
            cat('**Test de autocorrelaci√≥n de Breush-Godfrey**','\n\n')
            bg<-bgtest(regresion,order=3)
            print_kable(knitr::kable(tidy(bg))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(bg$p.value<0.05){cat("Existe autocorrelaci√≥n")
            }else{cat("No existe autocorrelaci√≥n")}
            cat('','\n\n')
          
          #Recomendaci√≥n de modelo cl√°sico o bootstrap. Se comprueba la distribuci√≥n.
          cat('','\n\n')
          cat('> **Modelo de estimaci√≥n recomendado**','\n\n')
            if(saph$p.value<0.05|lillie$p.value<0.05){cat("Distribuci√≥n no normal, se recomienda el uso de un modelo bootstrap")
            }else {cat("Distribuci√≥n normal, se recomienda el uso de un modelo cl√°sico")}
          cat('','\n\n')
        cat('###########################################################################','\n\n')    
      
        #Regresi√≥n bootstrap
          cat('> **Modelo de regresi√≥n bootstrap**','\n\n')
          set.seed(2)
          model.boot<-function(data,indices){
            sub.data<-data[indices,]
            model<-glm(mi_formula,data=sub.data)
            coef(model) }
          regresion.boot<-boot(dataframe,model.boot,R=100)
          print_kable(knitr::kable(tidy(regresion.boot))%>%kable_styling(bootstrap_options = "striped"))
          
          #Gr√°fico de la regresi√≥n
          cat('> **Gr√°ficos de la regresi√≥n bootstrap**','\n\n')
          plot(regresion.boot)
        
        
    } else {
        full <- glm(mi_formula,data=dataframe,family = binomial("logit"))
        null <- glm(mi_formula.null,data=dataframe,family = binomial("logit"))
        #Clasificaci√≥n cl√°sica
        #Chequeo de filtrado de variables
          if(filtrado=="backward"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC backward**','\n\n')
          clasificacion<-step(full, data=dataframe, scope=list(upper = full, lower = null), direction="backward",k=log(nrow(dataframe)))
          
          } else if (filtrado=="forward"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC forward**','\n\n')
          clasificacion<-step(null, data=dataframe, scope=list(upper = full, lower = null), direction="forward",k=log(nrow(dataframe)))
          } else if (filtrado=="stepwise"){
          cat('> **Selecci√≥n de variables seg√∫n valor de BIC stepwise**','\n\n')
          clasificacion<-step(null, data=dataframe, scope=list(upper = full, lower = null), direction="both",k=log(nrow(dataframe)))
          } else if (filtrado=="No"){
          clasificacion<-glm(mi_formula,data=dataframe,family=binomial(logit))
          }
        
          cat('','\n\n')
          cat('> **Modelo de clasificaci√≥n cl√°sica**','\n\n')
          print_kable(knitr::kable(tidy(clasificacion))%>%kable_styling(bootstrap_options = "striped"))
          
          #Medidas R2
          R2.clas<-nagelkerke(clasificacion,restrictNobs = T)
          cat('> **Medidas de R^2^**','\n\n')
          print_kable(knitr::kable(R2.clas$Pseudo.R.squared.for.model.vs.null)%>%kable_styling(bootstrap_options = "striped", full_width = F, position = "left"))
          
          cat('','\n\n')
          
          #Gr√°fico de la clasificaci√≥n
          cat('> **Gr√°ficos de la clasificaci√≥n**','\n\n')
          plot(clasificacion)
          
          cat('','\n\n')
        
          #Verificaci√≥n de las hip√≥tesis del Modelo Lineal al 95% de confianza
          cat('> **Verificaci√≥n de las hip√≥tesis del modelo lineal**','\n\n')
            #Test de heterocedasticidad de Breusch Pagan
            cat('**Test de heterocedasticidad de Breusch Pagan**','\n\n')
            bp.clas<-bptest(clasificacion)
            print_kable(knitr::kable(tidy(bp.clas))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(bp.clas$p.value<0.05){cat("Residuos heteroced√°sticos")
            }else{cat("Residuos homoced√°sticos")}
            
            cat('','\n\n')
            #Test de autocorrelacion de Breush-Godfrey
            cat('**Test de autocorrelaci√≥n de Breusch-Godfrey**','\n\n')
            bg.clas<-bgtest(clasificacion,order=3)
            print_kable(knitr::kable(tidy(bg.clas))%>%kable_styling(bootstrap_options = "striped",full_width = F, position = "left"))
            if(bg.clas$p.value<0.05){cat("Existe autocorrelaci√≥n")
            }else{cat("No existe autocorrelaci√≥n")}
        
          #Recomendaci√≥n de modelo cl√°sico o bootstrap. Se comprueba la distribuci√≥n.
          cat('','\n\n')
          cat('> **Modelo de estimaci√≥n recomendado**','\n\n')
          cat('Variable dependiente de tipo factor por lo que se recomienda el uso de un modelo bootstrap','\n\n')
        cat('###########################################################################','\n\n')    
        #Clasificaci√≥n bootstrap
          set.seed(3)
          model.boot<-function(data,indices){
            sub.data<-data[indices,]
            model<-glm(mi_formula,data=sub.data,family=binomial(logit))
            coef(model) }
          clasificacion.boot<-boot(data=as.data.frame(dataframe),model.boot,R=100)
          cat('> **Modelo de clasificaci√≥n bootstrap**','\n\n')
          print_kable(knitr::kable(tidy(clasificacion.boot))%>%kable_styling(bootstrap_options = "striped"))
          
          
          cat('','\n\n')
          
          #Gr√°fico de la clasificaci√≥n
          cat('> **Gr√°ficos de la clasificaci√≥n bootstrap**','\n\n')
          plot(clasificacion.boot)
    
  }

}
cat('','\n\n')
```

```{r results='asis'}
MLG("crim",BostonHousing,"forward")
```

```{r results='asis'}
MLG("class",german.bal,"backward")
```


## Ejercicio 2

### En el documento relativo a Introducci√≥n al Machine Learning se elabora un ejemplo de Miner√≠a de Datos utilizando la base de datos de german credit balanceada con 750 registros, 375 de cada clase. Uno de los modelos estimados ha sido un modelo Logit, obteniendo un √°rea bajo la curva ROC de 0,771, muy pr√≥xima a la del mejor modelo, el Random Forest, con un valor de 0,796.

### Es de esperar que un modelo GAM mejore el ajuste del GLM, pero ¬øsuperar√° al Random Forest? Para ello, elabore un GAM estudiando qu√© tipo de regresi√≥n utilizar (ajuste polin√≥mico o curvil√≠neo, Loess, spline de regresi√≥n o spline de suavizado) con cada una de las 3 variables independientes cuantitativas: duraci√≥n, montante y edad. Nota: la implementaci√≥n de caret no permite actualmente ajustar adecuadamente este tipo de modelos.

### Al igual que en el resto de los ejemplos, utilice una estimaci√≥n Bootstrap con 30 repeticiones para obtener las 5 m√©tricas planteadas en el documento. Compare estad√≠sticamente los resultados. Nota: puede calcular IC de AUC con la librer√≠a pROC, funciones auc() y ci.auc(). El resto de m√©tricas puede obtenerse a trav√©s de la matriz de confusi√≥n obtenida a partir de las r√©plicas Bootstrap (ojo, en el documento se muestra la matriz de confusi√≥n de los 750 datos, no de las r√©plicas).

```{r echo=FALSE}
datos<-readRDS("30184602-german.balanceado.RDS.bin")
# Redondeo variables num√©ricas, por ser en origen de tipo entero
datos$duration <- as.integer(round(datos$duration, 0))
datos$credit_amount <- as.integer(round(datos$credit_amount, 0))
datos$age <- as.integer(round(datos$age, 0))
```
Se opta por regresar con splines suavizadas de orden 3:
```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(mgcv)))
modelo<-gam(class ~ s(duration,k=3)+s(age,k=3)+s(credit_amount,k=3)+checking_status+credit_history+purpose+savings_status+employment+installment_commitment+personal_status+other_parties+residence_since+property_magnitude+other_payment_plans+housing+existing_credits+job+num_dependents+own_telephone+foreign_worker,data=datos,family=binomial)
kable(tidy(modelo))%>%kable_styling(bootstrap_options = "striped")
```
Se realiza la predicci√≥n del modelo GAM. Se asigna el valor "bad" a los valores predichos entre 0 y 0.5, se asigna el valor "good" a los valores entre 0.5 y 1. Esto se hace para que los valores observados y los valores predichos tengan los mismos niveles:
```{r echo=FALSE}
prediccion<-predict.gam(modelo,type="response")
prediccion.AUC<-predict.gam(modelo,type="response")
# Los rownames son correctos, no tocar.
# Valor de los factores de datos$class son "bad" y "good".
for(i in 1:length(prediccion)){
  if(prediccion[i]<=0.5){
    prediccion[i]<- "bad"
  }
  else {
    prediccion[i]<-"good"
  }
}
# Establecemos como factor el output de la predicci√≥n para que pueda cruzarse con el factor de los datos muestrales en la matriz de confusi√≥n:
prediccion<-as.factor(prediccion)
```
Se calcula la matriz de confusi√≥n para obtener las m√©tricas de sensibilidad, especificidad, precisi√≥n y estad√≠stico kappa:
```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(caret)))
suppressWarnings(suppressPackageStartupMessages(library(ggplot2)))
suppressWarnings(suppressPackageStartupMessages(library(lattice)))
conf.Matrix<-confusionMatrix(prediccion,datos$class)
conf.Matrix.acc.kapp<-conf.Matrix$overall[1:2]
conf.Matrix.sens.spec<-conf.Matrix$byClass[1:2]
```
La sensibilidad del modelo GAM es `r conf.Matrix$byClass[1]`

La especificidad del modelo GAM es `r conf.Matrix$byClass[2]`

La precisi√≥n (accuracy) del modelo GAM es `r conf.Matrix$overall[1]`

El √≠ndice kappa del modelo GAM es `r conf.Matrix$overall[2]`

Se calcula la m√©trica ROC para el modelo GAM:
```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(pROC)))
AUC.metric<-roc(response=datos$class,predictor=as.numeric(prediccion.AUC))
ROC.metric<-AUC.metric$auc
```
El ROC del modelo GAM es `r AUC.metric$auc`

Se imprime la curva ROC del modelo GAM:
```{r echo=FALSE}
plot.roc(AUC.metric)
```


Se genera una tabla resumen con las 5 m√©tricas obtenidas en el modelo GAM y se compara con las m√©tricas obtenidas en el Random Forest:
```{r echo=FALSE}
# Se crea manualmente un vector con las m√©tricas del random forest del documento "04_Introducci√≥n al machine learning"
RF<-c(0.7242,0.7242,0.7230,0.4467,0.7962)
names.metrics<-c("Sensitivity","Specificity","Accuracy","Kappa","ROC")

metricas.gam.rf<-c(conf.Matrix.sens.spec,conf.Matrix.acc.kapp,ROC.metric,RF)
metricas.gam.rf<-matrix(data=metricas.gam.rf,ncol=2,dimnames = list(names.metrics,c("GAM","RF")))

suppressWarnings(suppressPackageStartupMessages(library("kableExtra")))
metricas.gam.rf%>%
   kbl(caption = "Tabla de m√©tricas") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)

```

#### Conclusi√≥n:

El modelo GAM ha obtenido un ROC de `r AUC.metric$auc` superior al random forest que obtuvo un ROC de 0.7962.

El resto de las m√©tricas tambi√©n han obtenido un resultado mejor.

Por tanto, el modelo GAM se considera un modelo preferible para realizar inferencia sobre el conjunto de datos muestrales.

  
## Ejercicio 3
### La base de datos environmental de la librer√≠a lattice presenta las mediciones diarias de concentraci√≥n de ozono, velocidad del viento, temperatura y radiaci√≥n solar en la ciudad de Nueva York de mayo a septiembre de 1973. En concreto, se dispone de 111 observaciones con la siguiente informaci√≥n:
### ‚Ä¢ Ozono. Concentraci√≥n promedio de ozono (mediciones por hora) en partes por bill√≥n.
### ‚Ä¢ Radiaci√≥n. Radiaci√≥n solar (de 08:00 a 12:00) en langleys.
### ‚Ä¢ Temperatura. Temperatura m√°xima diaria en grados Fahrenheit.
### ‚Ä¢ Viento. Velocidad promedio del viento (a las 07:00 y 10:00) en millas por hora.
### En base a otros estudios, los coeficientes beta o, lo que es lo mismo, el aumento de la concentraci√≥n de ozono seg√∫n se var√≠en las condiciones clim√°ticas en una unidad, pueden acotarse del siguiente modo (aproximadamente a un 95% de confianza): radiaci√≥n 0,05 a 0,15, temperatura 1,3 a 1,7 y viento -3,7 a -3,3. Supondremos la no existencia de covarianzas.
### Para la precisi√≥n (inversa de la varianza residual), considere como par√°metros de la funci√≥n gamma las dos siguientes: c0 = 56 y d0 = 24649.
### Estime un segundo modelo sin incluir estimaciones a priori de los coeficientes beta y sus varianzas, considerando c0 = d0 = 100.
### Estime un tercero sin incorporar informaci√≥n a priori. Comente cu√°l es la parametrizaci√≥n por defecto y razone lo que esto implica.
### Compare los resultados con un modelo de regresi√≥n lineal cl√°sico o frecuentista. Nota: la esperanza y varianza del error residual en la regresi√≥n lineal cl√°sica es: 
### ùê∏($ùëÜùëÖ^2$)=$ùúé^2$ y ùëâùëéùëü($ùëÜùëÖ^2$)= $2 ùúé^4$ / $(ùëõ‚àíùëò‚àí1)$
### Por √∫ltimo, estime un modelo Loess, comp√°relo con el resto y establezca las pertinentes conclusiones. Determine, razonadamente, cu√°l de ellos ser√≠a el de mayor desempe√±o.


```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(lattice)))
datos<-as.data.frame(environmental)
```
Se calculan las medias a priori de los coeficientes, la media del t√©rmino independiente se establece en cero puesto que no se da informaci√≥n en el enunciado.
```{r echo=FALSE}
b0_radiation<-mean(c(0.05,0.15))
b0_temperature<-mean(c(1.3,1.7))
b0_wind<-mean(c(-3.7,-3.3))
b0.vector<-c(0,b0_radiation,b0_temperature,b0_wind)
```
El vector de medias es `r b0.vector` .  

Se calculan las precisiones a priori de los coeficientes, la precision del t√©rmino independiente se establece en cero.
```{r echo=FALSE}
b0_radiation.prec<-(((0.05-b0_radiation)^2+(0.15-b0_radiation)^2))^-1
b0_temperature.prec<-(((1.3-b0_temperature)^2+(1.7-b0_temperature)^2))^-1
b0_wind.prec<-(((-3.7-b0_wind)^2+(-3.3-b0_wind)^2))^-1
B0.vector.prec<-c(0,b0_radiation.prec,b0_temperature.prec,b0_wind.prec)
```
El vector de precisiones  es `r B0.vector.prec`.  

Se realiza la estimaci√≥n modelo.1 con los coeficientes y varianzas a priori y considerando c0=56 y d0=24649:
```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library("MCMCpack")))
modelo.1<-MCMCregress(ozone~radiation+temperature+wind,data=datos,b0=b0.vector,B0=B0.vector.prec,c0=56,d0=24649)
# Se crea una tabla para presentar el resultado de la estimaci√≥n.
mean.modelo.1<-apply(modelo.1,2,mean)
sd.modelo.1<-apply(modelo.1,2,sd)
param.modelo.1<-colnames(modelo.1)
tabla.modelo.1<-matrix(data=c(mean.modelo.1,sd.modelo.1),ncol=2,byrow=F,dimnames=list(param.modelo.1,c("mean","sd")))
tabla.modelo.1%>%
   kbl(caption = "Modelo.1") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)
```
Se realiza la estimaci√≥n modelo.2 sin incluir estimaciones a priori de los coeficientes beta ni sus precisiones, considerando c0 = d0 = 100:
```{r echo=FALSE}
modelo.2<-MCMCregress(ozone~radiation+temperature+wind,data=datos,c0=100,d0=100)
# Se crea una tabla para presentar el resultado de la estimaci√≥n.
mean.modelo.2<-apply(modelo.2,2,mean)
sd.modelo.2<-apply(modelo.2,2,sd)
param.modelo.2<-colnames(modelo.2)
tabla.modelo.2<-matrix(data=c(mean.modelo.2,sd.modelo.2),ncol=2,byrow=F,dimnames=list(param.modelo.2,c("mean","sd")))
tabla.modelo.2%>%
   kbl(caption = "Modelo.2") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)
```
Se realiza la estimaci√≥n modelo.3 sin incluir informaci√≥n a priori:
```{r echo=FALSE}
modelo.3<-MCMCregress(ozone~radiation+temperature+wind,data=datos)
# Se crea una tabla para presentar el resultado de la estimaci√≥n.
mean.modelo.3<-apply(modelo.3,2,mean)
sd.modelo.3<-apply(modelo.3,2,sd)
param.modelo.3<-colnames(modelo.3)
tabla.modelo.3<-matrix(data=c(mean.modelo.3,sd.modelo.3),ncol=2,byrow=F,dimnames=list(param.modelo.3,c("mean","sd")))
tabla.modelo.3%>%
   kbl(caption = "Modelo.3") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)
```
La parametrizaci√≥n por defecto es MCMCregress(formula, data = NULL, burnin = 1000, mcmc = 10000, thin = 1, verbose = 0, seed = NA, beta.start = NA, b0 = 0, B0 = 0, c0 = 0.001, d0 = 0.001, sigma.mu = NA, sigma.var = NA, marginal.likelihood = c(‚Äúnone‚Äù, ‚ÄúLaplace‚Äù, ‚ÄúChib95‚Äù), ‚Ä¶) , la cual es el supuesto no informativo, y por lo tanto sus resultados ser√°n calculados teniendo en cuenta √∫nicamente la muestra de datos. Por defecto, el burnin (per√≠odo de adaptaci√≥n a la distribuci√≥n estacionaria) es de 1.000 repeticiones, seg√∫n el algoritmo Metropolis se establece el punto muestral candidato desde el que se generan 10.000 muestras (mcmc=10.000), el argumento thin=1 implica que no se establecen intervalos en la simulaci√≥n, verbose=0 implica que no se imprime en pantalla ni el vector beta ni el error de varianza de cada iteraci√≥n, seed=NA el sistema establece un valor de 12345, beta.start= NA implica que se emplean todos los betas, b0=0 implica que no se cargan las medias a priori de los betas, B0=0 implica que no se cargan precisiones a priori de los betas, c0=0.001 implica que no se aporta informaci√≥n de la forma de la gamma inversa a priori, d0=0.001 implica que no se aporta informaci√≥n de la escala de la gamma inversa a priori, sigma.mu=NA implica que no se aporta la media de la gamma inversa a priori, sima.VAR=NA implica que no se aporta la varianza de la gamma inversa a priori.

Al establecer el valor de B0=0 los par√°metros tendr√°n varianza infinita (precisi√≥n cero), y como adem√°s no se ha introducido informaci√≥n a priori,los resultados obtenidos por el modelo (no informativo) ser√°n muy similares a los obtenidos mediante una regresi√≥n cl√°sica.

Se realiza la estimaci√≥n modelo.4 de regresi√≥n lineal cl√°sico:
```{r echo=FALSE}
modelo.4<-lm(ozone~radiation+temperature+wind,data=datos)
tidy(modelo.4)%>%
   kbl(caption = "Modelo.4") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)
```
Se realiza la estimaci√≥n modelo.5 mediante LOESS:
```{r echo=FALSE}
modelo.5<-loess(ozone~radiation+temperature+wind,data=datos)
param.modelo.5<-modelo.5[c(4,5,8)]
nombres.param.modelo.5<-c("Equivalent Number of Parameters","Residual Standard Error","Trace of smoother matrix")
tabla.modelo.5<-matrix(data=param.modelo.5,byrow = T,ncol=3,dimnames = list("loess",nombres.param.modelo.5))
tabla.modelo.5%>%
   kbl(caption = "Modelo.5") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),full_width = F)
```
##### Comparaci√≥n de resultados entre modelos:

Se realiza la comparaci√≥n del error cuadr√°tico medio (SME) de los 5 modelos estimados, para ello se calculan los residuos (diferencia entre los valores observados y los valores estimados de la variable ozono) para cada uno de los modelos estimados. Estos residuos se elevan al cuadrado y se calcula su media. El valor resultante es el SME, y ser√° la m√©trica utilizada para comparar los modelos estimados.


```{r echo=FALSE}
#Modelo.1
X <- model.matrix(~radiation+temperature+wind, data=datos)
# Se calcula la media de los parametros del modelo 1: MCMC
coefs.1<-apply(modelo.1,2,mean)[1:4]
# Se calcula la prediccion
pred.1<-X %*% coefs.1
# Residuos
resids.1<-pred.1-datos$ozone
# SME
SME.1<-mean(resids.1^2)
```

```{r echo=FALSE}
#Modelo.2
coefs.2<-apply(modelo.2,2,mean)[1:4]
# Se calcula la prediccion
pred.2<-X %*% coefs.2
# Residuos
resids.2<-pred.2-datos$ozone
# SME
SME.2<-mean(resids.2^2)
``` 

```{r echo=FALSE}
#Modelo.3
coefs.3<-apply(modelo.3,2,mean)[1:4]
# Se calcula la prediccion
pred.3<-X %*% coefs.3
# Residuos
resids.3<-pred.3-datos$ozone
# SME
SME.3<-mean(resids.3^2)
```

```{r echo=FALSE}
#Modelo 4: LM
SME.4<-mean(modelo.4$residuals^2)
```

```{r echo=FALSE}
#Modelo 5: LOESS
SME.5<-mean(modelo.5$residuals^2)
```
Se genera una tabla comparativa:  
```{r echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library("kableExtra")))
SME.vector<-c(SME.1,SME.2,SME.3,SME.4,SME.5)
modelo.vector<-c("Bayesiano","Bayesiano","Bayesiano","Regresi√≥n cl√°sica","Loess")
tipo.vector<-c("Param√©trica","Param√©trica","Param√©trica","Param√©trica","No param√©trica")
nombre.col<-c("Clase de modelo","Tipo de regresi√≥n","Error cuadr√°tico medio")
nombre.fil<-c("Modelo 1","Modelo 2","Modelo 3","Modelo 4","Modelo 5")
SME.matrix<-matrix(data=c(modelo.vector,tipo.vector,SME.vector),ncol=3,dimnames = list(nombre.fil,nombre.col))
SME.matrix%>%
   kbl(caption = "Comparaci√≥n de modelos estimados") %>%
   kable_paper(full_width = F)%>%
   kable_styling(bootstrap_options = c("striped", "hover"),position = "float_left")
```

#####  Conclusi√≥n:
Se observa que el modelo con menor SME es el modelo 5, que se corresponde con la estimaci√≥n LOESS. La diferencia del error cuadr√°tico medio entre los otros cuatro modelos estimados es muy peque√±a, de lo que deducimos que en este conjunto de datos no resulta √∫til la informaci√≥n a priori de cara a estimar la informaci√≥n a posteriori. El modelo LM ha obtenido un error cuadr√°tico medio muy similar a los modelos bayesianos. El modelo Loess ha obtenido el error cuadr√°tico medio m√°s bajo, por lo que resulta el modelo m√°s adecuado para utilizar con la muestra estudiada. La regresi√≥n no param√©trica se desmarca de la regresi√≥n param√©trica y se elige como el modelo m√°s adecuado para realizar inferencia sobre el conjunto de datos "enviromental".


